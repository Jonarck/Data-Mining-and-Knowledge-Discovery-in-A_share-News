{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6b75f5d",
   "metadata": {},
   "source": [
    "# DSAA 5002 - Data Mining and Knowledge Discovery in Data Science\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df9ffec",
   "metadata": {},
   "source": [
    "# Task 2 (50 marks) Application of Knowledge Graph\n",
    "\n",
    "**Background:** \n",
    "**In addition to explicitly mentioning listed companies, each news article may also implicitly impact the other \n",
    "companies, either positively or negatively.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8d77dd",
   "metadata": {},
   "source": [
    "# Q4 Knowledge-Driven Financial Analysis\n",
    "---\n",
    "\n",
    "## 1. Generate related company impact domain - a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2bb5d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Step 1: Read relevant tables\n",
    "# Read node information table\n",
    "nodes_df = pd.read_csv(r'KnowledgeGraph\\hidy.nodes.company.csv')\n",
    "\n",
    "# Read relationship information tables\n",
    "compete_df = pd.read_csv(r'KnowledgeGraph\\hidy.relationships.compete.csv')\n",
    "cooperate_df = pd.read_csv(r'KnowledgeGraph\\hidy.relationships.cooperate.csv')\n",
    "dispute_df = pd.read_csv(r'KnowledgeGraph\\hidy.relationships.dispute.csv')\n",
    "invest_df = pd.read_csv(r'KnowledgeGraph\\hidy.relationships.invest.csv')\n",
    "same_industry_df = pd.read_csv(r'KnowledgeGraph\\hidy.relationships.same_industry.csv')\n",
    "supply_df = pd.read_csv(r'KnowledgeGraph\\hidy.relationships.supply.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2a4cf23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|█████████████████████████████████████████████████████████████████| 3974/3974 [00:17<00:00, 228.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # Importing the tqdm module\n",
    "\n",
    "company_relation = nodes_df.copy()\n",
    "\n",
    "# Step 2: Iterate through each row of the node information table\n",
    "for index, row in tqdm(company_relation.iterrows(), total=len(company_relation), desc='Processing'):\n",
    "    company_id = row[':ID']  # Fetching the ID of the company\n",
    "    \n",
    "    same_impact_company_ID_set = set()\n",
    "    opposite_impact_company_ID_set = set()\n",
    "    \n",
    "    # Searching for IDs of other companies related to this company in the relationship tables\n",
    "    # Please check and add to the respective sets based on each type of relationship\n",
    "    \n",
    "    # Searching for related company IDs in 'hidy.relationships.invest.csv' and 'hidy.relationships.supply.csv' tables\n",
    "    invest_related = invest_df[invest_df[':START_ID'] == company_id]\n",
    "    supply_related = supply_df[supply_df[':START_ID'] == company_id]\n",
    "    # Adding ':END_ID' values of related rows to the sets\n",
    "    same_impact_company_ID_set.update(set(invest_related[':END_ID'].values))\n",
    "    same_impact_company_ID_set.update(set(supply_related[':END_ID'].values))\n",
    "\n",
    "    # Searching for related company IDs in 'hidy.relationships.cooperate.csv' and 'hidy.relationships.same_industry.csv' tables\n",
    "    cooperate_related = cooperate_df[(cooperate_df[':START_ID'] == company_id) | (cooperate_df[':END_ID'] == company_id)]\n",
    "    same_industry_related = same_industry_df[(same_industry_df[':START_ID'] == company_id) | (same_industry_df[':END_ID'] == company_id)]\n",
    "    # Adding ':START_ID' and ':END_ID' values of related rows to the sets\n",
    "    same_impact_company_ID_set.update(set(cooperate_related[':START_ID'].values))\n",
    "    same_impact_company_ID_set.update(set(cooperate_related[':END_ID'].values))\n",
    "    same_impact_company_ID_set.update(set(same_industry_related[':START_ID'].values))\n",
    "    same_impact_company_ID_set.update(set(same_industry_related[':END_ID'].values))\n",
    "\n",
    "    # Searching for related company IDs in 'hidy.relationships.compete.csv' and 'hidy.relationships.dispute.csv' tables\n",
    "    compete_related = compete_df[(compete_df[':START_ID'] == company_id) | (compete_df[':END_ID'] == company_id)]\n",
    "    dispute_related = dispute_df[(dispute_df[':START_ID'] == company_id) | (dispute_df[':END_ID'] == company_id)]\n",
    "    # Adding ':START_ID' and ':END_ID' values of related rows to the sets\n",
    "    opposite_impact_company_ID_set.update(set(compete_related[':START_ID'].values))\n",
    "    opposite_impact_company_ID_set.update(set(compete_related[':END_ID'].values))\n",
    "    opposite_impact_company_ID_set.update(set(dispute_related[':START_ID'].values))\n",
    "    opposite_impact_company_ID_set.update(set(dispute_related[':END_ID'].values))\n",
    "    \n",
    "\n",
    "    # Creating two lists to store the company names that have same and opposite impacts\n",
    "    same_impact_company_list = []\n",
    "    opposite_impact_company_list = []\n",
    "\n",
    "    # Iterating through the related IDs and fetching the corresponding company names from the node information table, adding them to the lists\n",
    "    for company_id in same_impact_company_ID_set:\n",
    "        company_name = nodes_df[nodes_df[':ID'] == company_id]['company_name'].values\n",
    "        if len(company_name) > 0:\n",
    "            same_impact_company_list.extend(company_name)\n",
    "\n",
    "    for company_id in opposite_impact_company_ID_set:\n",
    "        company_name = nodes_df[nodes_df[':ID'] == company_id]['company_name'].values\n",
    "        if len(company_name) > 0:\n",
    "            opposite_impact_company_list.extend(company_name)\n",
    "    \n",
    "    # Adding the obtained company name lists to the corresponding columns in the 'company_relation' DataFrame\n",
    "    if len(same_impact_company_list)  != 0:\n",
    "        company_relation.at[index,'same_impact_company'] = \", \".join(same_impact_company_list)\n",
    "    if len(opposite_impact_company_list)  != 0:\n",
    "        company_relation.at[index,'opposite_impact_company'] = \", \".join(opposite_impact_company_list)\n",
    "    \n",
    "# Storing the results into an Excel file\n",
    "company_relation.to_excel(r'KnowledgeGraph\\company_relationship.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b094eed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>:ID</th>\n",
       "      <th>company_name</th>\n",
       "      <th>code</th>\n",
       "      <th>:LABEL</th>\n",
       "      <th>same_impact_company</th>\n",
       "      <th>opposite_impact_company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>东诚药业</td>\n",
       "      <td>002675.SZ</td>\n",
       "      <td>company</td>\n",
       "      <td>东诚药业, 同仁堂, 海翔药业, 福安药业</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>大庆华科</td>\n",
       "      <td>000985.SZ</td>\n",
       "      <td>company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>恒辉安防</td>\n",
       "      <td>300952.SZ</td>\n",
       "      <td>company</td>\n",
       "      <td>朗科智能, 恒辉安防, 彤程新材</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>康跃科技</td>\n",
       "      <td>300391.SZ</td>\n",
       "      <td>company</td>\n",
       "      <td>以岭药业, 康跃科技</td>\n",
       "      <td>恒通科技, 康跃科技</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>诚益通</td>\n",
       "      <td>300430.SZ</td>\n",
       "      <td>company</td>\n",
       "      <td>大湖股份, 诚益通</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>3969</td>\n",
       "      <td>圣诺生物</td>\n",
       "      <td>688117.SH</td>\n",
       "      <td>company</td>\n",
       "      <td>圣诺生物, 上声电子</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>3970</td>\n",
       "      <td>牧原股份</td>\n",
       "      <td>002714.SZ</td>\n",
       "      <td>company</td>\n",
       "      <td>新希望, 牧原股份, 海螺水泥, 光大银行, 中牧股份, 智动力, 温氏股份, 立华股份, ...</td>\n",
       "      <td>牧原股份, 招商证券</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>3971</td>\n",
       "      <td>中航高科</td>\n",
       "      <td>600862.SH</td>\n",
       "      <td>company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>3972</td>\n",
       "      <td>江丰电子</td>\n",
       "      <td>300666.SZ</td>\n",
       "      <td>company</td>\n",
       "      <td>北京君正, 紫光国微, 江丰电子, 秦川机床, 雅克科技, 亿通科技, 贵研铂业, 沪硅产业...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>3973</td>\n",
       "      <td>珍宝岛</td>\n",
       "      <td>603567.SH</td>\n",
       "      <td>company</td>\n",
       "      <td>以岭药业, 浙江震元, 珍宝岛, 药明康德</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3974 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       :ID company_name       code   :LABEL  \\\n",
       "0        0         东诚药业  002675.SZ  company   \n",
       "1        1         大庆华科  000985.SZ  company   \n",
       "2        2         恒辉安防  300952.SZ  company   \n",
       "3        3         康跃科技  300391.SZ  company   \n",
       "4        4          诚益通  300430.SZ  company   \n",
       "...    ...          ...        ...      ...   \n",
       "3969  3969         圣诺生物  688117.SH  company   \n",
       "3970  3970         牧原股份  002714.SZ  company   \n",
       "3971  3971         中航高科  600862.SH  company   \n",
       "3972  3972         江丰电子  300666.SZ  company   \n",
       "3973  3973          珍宝岛  603567.SH  company   \n",
       "\n",
       "                                    same_impact_company  \\\n",
       "0                                 东诚药业, 同仁堂, 海翔药业, 福安药业   \n",
       "1                                                   NaN   \n",
       "2                                      朗科智能, 恒辉安防, 彤程新材   \n",
       "3                                            以岭药业, 康跃科技   \n",
       "4                                             大湖股份, 诚益通   \n",
       "...                                                 ...   \n",
       "3969                                         圣诺生物, 上声电子   \n",
       "3970  新希望, 牧原股份, 海螺水泥, 光大银行, 中牧股份, 智动力, 温氏股份, 立华股份, ...   \n",
       "3971                                                NaN   \n",
       "3972  北京君正, 紫光国微, 江丰电子, 秦川机床, 雅克科技, 亿通科技, 贵研铂业, 沪硅产业...   \n",
       "3973                              以岭药业, 浙江震元, 珍宝岛, 药明康德   \n",
       "\n",
       "     opposite_impact_company  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "3                 恒通科技, 康跃科技  \n",
       "4                        NaN  \n",
       "...                      ...  \n",
       "3969                     NaN  \n",
       "3970              牧原股份, 招商证券  \n",
       "3971                     NaN  \n",
       "3972                     NaN  \n",
       "3973                     NaN  \n",
       "\n",
       "[3974 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_relation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab54ac7",
   "metadata": {},
   "source": [
    "## 2. Generate the Knowledge-Driven Financial Analysis result use the table above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c622f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_relation = pd.read_excel(r'KnowledgeGraph\\company_relationship.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a892a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Application_set.xlsx\n",
    "source_file = r'Result_dataset\\\\Application_set_BiLSTM\\\\Application_set_labeled_with_BiLSTM_v2.xlsx'\n",
    "df = pd.read_excel(source_file)\n",
    "\n",
    "# Adding two new columns \"Implicit_Positive_Company\" and \"Implicit_Negative_Company\" in Analysis_set.xlsx\n",
    "df['Implicit_Positive_Company'] = \"\"\n",
    "df['Implicit_Negative_Company'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2acdbdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|█████████████████████████████████████████████████████████████| 524226/524226 [18:50<00:00, 463.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # Importing tqdm module\n",
    "\n",
    "# Iterating over each row in Application_set.xlsx\n",
    "for index, row in tqdm(df.iterrows(), total=len(df), desc='Processing'):\n",
    "    explicit_companies = row['Explicit_Company'].split(', ')\n",
    "    \n",
    "    # Step 1: Creating two sets for same impact companies and opposite impact companies\n",
    "    same_impact_company_set = set()\n",
    "    opposite_impact_company_set = set()\n",
    "    \n",
    "    # Step 2: Iterating over each company in Explicit_Company\n",
    "    for company in explicit_companies:\n",
    "        # Finding company ID\n",
    "        if_company_id_in_companies_name = company_relation[nodes_df['company_name'] == company][':ID'].values\n",
    "        if len(if_company_id_in_companies_name) == 0:\n",
    "            continue\n",
    "        company_id = if_company_id_in_companies_name[0]\n",
    "        \n",
    "        same_impact_company_series = company_relation.loc[company_relation[':ID'] == company_id][\"same_impact_company\"]\n",
    "        same_impact_company_of_this_company = same_impact_company_series.apply(lambda x: x.split(', ') if isinstance(x, str) else [])\n",
    "        if len(same_impact_company_of_this_company.iloc[0]) != 0:\n",
    "            same_impact_company_set.update(set(str(x) for x in same_impact_company_of_this_company.explode()))\n",
    "\n",
    "        opposite_impact_company_series = company_relation.loc[company_relation[':ID'] == company_id][\"opposite_impact_company\"]\n",
    "        opposite_impact_company_of_this_company = opposite_impact_company_series.apply(lambda x: x.split(', ') if isinstance(x, str) else [])\n",
    "        if len(opposite_impact_company_of_this_company.iloc[0]) != 0:        \n",
    "            opposite_impact_company_set.update(set(str(x) for x in opposite_impact_company_of_this_company.explode()))\n",
    "\n",
    "    # Step 3: Populating based on label values\n",
    "    if row['label'] == 1:\n",
    "        df.at[index, 'Implicit_Positive_Company'] = ', '.join(same_impact_company_set) if same_impact_company_set else 'None'\n",
    "        df.at[index, 'Implicit_Negative_Company'] = ', '.join(opposite_impact_company_set) if opposite_impact_company_set else 'None'\n",
    "    elif row['label'] == 0:\n",
    "        df.at[index, 'Implicit_Positive_Company'] = ', '.join(opposite_impact_company_set) if opposite_impact_company_set else 'None'\n",
    "        df.at[index, 'Implicit_Negative_Company'] = ', '.join(same_impact_company_set) if same_impact_company_set else 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88e22bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsID</th>\n",
       "      <th>NewsContent</th>\n",
       "      <th>Explicit_Company</th>\n",
       "      <th>label</th>\n",
       "      <th>Implicit_Positive_Company</th>\n",
       "      <th>Implicit_Negative_Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>建设银行原董事长张恩照一审被判15年 　　本报记者 田雨 李京华    　　中国建设银行股份...</td>\n",
       "      <td>建设银行</td>\n",
       "      <td>0</td>\n",
       "      <td>任子行, 捷捷微电, 建设银行</td>\n",
       "      <td>上海银行, 中国人寿, 中金公司, 民生银行, 怡亚通, 兴业银行, 平安银行, 贵州茅台,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>农行信用卡中心搬到上海滩 　　中国农业银行信用卡中心由北京搬到上海了！  　　农行行长杨明生...</td>\n",
       "      <td>农业银行</td>\n",
       "      <td>1</td>\n",
       "      <td>上海银行, 中国国航, TCL集团, 中国神华, 兴业银行, 山东矿机, 申万宏源, 中信证...</td>\n",
       "      <td>ST云维, 农业银行</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>外运发展：价值型蓝筹股补涨要求强烈 　　在新基金快速发行以及申购资金回流的情况下，市场总体上...</td>\n",
       "      <td>中国国航, 外运发展</td>\n",
       "      <td>1</td>\n",
       "      <td>中国国航, 中国石化, 南方航空, 寒武纪, 中国外运, 中国电建, 吉祥航空, 山航B, ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>胜利股份：稳步走强形成标准上升通道 　　胜利股份（000407）公司子公司填海造地2800亩...</td>\n",
       "      <td>胜利股份</td>\n",
       "      <td>1</td>\n",
       "      <td>新疆浩源, 特锐德, 胜利股份</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[港股快讯]恒指收市报18960点 成交467亿港元 　　全景网11月30日讯 外围股市造好...</td>\n",
       "      <td>新世界股份</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524221</th>\n",
       "      <td>1037031</td>\n",
       "      <td>亿华通：公司电解槽相关产品目前还处于产品的研发及测试阶段 尚未实现批量销售 每经AI快讯，有...</td>\n",
       "      <td>亿华通</td>\n",
       "      <td>1</td>\n",
       "      <td>仕佳光子, 东风汽车, 中国船舶, 亿华通, 福田汽车, 百奥泰, 宝泰隆</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524222</th>\n",
       "      <td>1037032</td>\n",
       "      <td>依米康：接受中泰证券调研 依米康（SZ 300249，收盘价：10.38元）发布公告称，20...</td>\n",
       "      <td>中泰证券, 依米康</td>\n",
       "      <td>1</td>\n",
       "      <td>龙磁科技, 乐歌股份, 中金公司, 国新能源, 中国平安, 东方证券, 申万宏源, 中信证券...</td>\n",
       "      <td>西水股份, 华谊嘉信, 中泰证券</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524223</th>\n",
       "      <td>1037033</td>\n",
       "      <td>天风证券给予中核科技买入评级 核电行业景气上行 公司有望乘风而起 天风证券10月13日发布研...</td>\n",
       "      <td>天风证券, 中核科技</td>\n",
       "      <td>1</td>\n",
       "      <td>西南证券, 久远银海, 凯撒文化, 国信证券, 中金公司, 闻泰科技, 华泰证券, 上海临港...</td>\n",
       "      <td>三特索道, 天风证券, 吉翔股份, 中源家居</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524224</th>\n",
       "      <td>1037034</td>\n",
       "      <td>海特生物：公司在抗癌药CPT获批后 会考虑适时开展CPT在海外的临床并谋求上市 有投资者提问...</td>\n",
       "      <td>海特生物</td>\n",
       "      <td>1</td>\n",
       "      <td>药明康德, 海特生物, 海尔生物</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524225</th>\n",
       "      <td>1037035</td>\n",
       "      <td>恩捷股份：股东合益投资部分股份补充质押 10月13日午间，根据恩捷股份发布的公告，持有公司股...</td>\n",
       "      <td>恩捷股份</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>福耀玻璃, 亿纬锂能, 云南白药, 天赐材料, 平安银行, 金辰股份, 中兴通讯, 德尔股份...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>524226 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         NewsID                                        NewsContent  \\\n",
       "0             1  建设银行原董事长张恩照一审被判15年 　　本报记者 田雨 李京华    　　中国建设银行股份...   \n",
       "1             2  农行信用卡中心搬到上海滩 　　中国农业银行信用卡中心由北京搬到上海了！  　　农行行长杨明生...   \n",
       "2             3  外运发展：价值型蓝筹股补涨要求强烈 　　在新基金快速发行以及申购资金回流的情况下，市场总体上...   \n",
       "3             4  胜利股份：稳步走强形成标准上升通道 　　胜利股份（000407）公司子公司填海造地2800亩...   \n",
       "4             5  [港股快讯]恒指收市报18960点 成交467亿港元 　　全景网11月30日讯 外围股市造好...   \n",
       "...         ...                                                ...   \n",
       "524221  1037031  亿华通：公司电解槽相关产品目前还处于产品的研发及测试阶段 尚未实现批量销售 每经AI快讯，有...   \n",
       "524222  1037032  依米康：接受中泰证券调研 依米康（SZ 300249，收盘价：10.38元）发布公告称，20...   \n",
       "524223  1037033  天风证券给予中核科技买入评级 核电行业景气上行 公司有望乘风而起 天风证券10月13日发布研...   \n",
       "524224  1037034  海特生物：公司在抗癌药CPT获批后 会考虑适时开展CPT在海外的临床并谋求上市 有投资者提问...   \n",
       "524225  1037035  恩捷股份：股东合益投资部分股份补充质押 10月13日午间，根据恩捷股份发布的公告，持有公司股...   \n",
       "\n",
       "       Explicit_Company  label  \\\n",
       "0                  建设银行      0   \n",
       "1                  农业银行      1   \n",
       "2            中国国航, 外运发展      1   \n",
       "3                  胜利股份      1   \n",
       "4                 新世界股份      1   \n",
       "...                 ...    ...   \n",
       "524221              亿华通      1   \n",
       "524222        中泰证券, 依米康      1   \n",
       "524223       天风证券, 中核科技      1   \n",
       "524224             海特生物      1   \n",
       "524225             恩捷股份      0   \n",
       "\n",
       "                                Implicit_Positive_Company  \\\n",
       "0                                         任子行, 捷捷微电, 建设银行   \n",
       "1       上海银行, 中国国航, TCL集团, 中国神华, 兴业银行, 山东矿机, 申万宏源, 中信证...   \n",
       "2       中国国航, 中国石化, 南方航空, 寒武纪, 中国外运, 中国电建, 吉祥航空, 山航B, ...   \n",
       "3                                         新疆浩源, 特锐德, 胜利股份   \n",
       "4                                                    None   \n",
       "...                                                   ...   \n",
       "524221              仕佳光子, 东风汽车, 中国船舶, 亿华通, 福田汽车, 百奥泰, 宝泰隆   \n",
       "524222  龙磁科技, 乐歌股份, 中金公司, 国新能源, 中国平安, 东方证券, 申万宏源, 中信证券...   \n",
       "524223  西南证券, 久远银海, 凯撒文化, 国信证券, 中金公司, 闻泰科技, 华泰证券, 上海临港...   \n",
       "524224                                   药明康德, 海特生物, 海尔生物   \n",
       "524225                                               None   \n",
       "\n",
       "                                Implicit_Negative_Company  \n",
       "0       上海银行, 中国人寿, 中金公司, 民生银行, 怡亚通, 兴业银行, 平安银行, 贵州茅台,...  \n",
       "1                                              ST云维, 农业银行  \n",
       "2                                                    None  \n",
       "3                                                    None  \n",
       "4                                                    None  \n",
       "...                                                   ...  \n",
       "524221                                               None  \n",
       "524222                                   西水股份, 华谊嘉信, 中泰证券  \n",
       "524223                             三特索道, 天风证券, 吉翔股份, 中源家居  \n",
       "524224                                               None  \n",
       "524225  福耀玻璃, 亿纬锂能, 云南白药, 天赐材料, 平安银行, 金辰股份, 中兴通讯, 德尔股份...  \n",
       "\n",
       "[524226 rows x 6 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391e51a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis_set.xlsx is our Task2.xlsx\n",
    "destination_file = r'Result_dataset\\\\Analysis_set_BiLSTM\\\\Analysis_set_labeled_with_BiLSTM_v1.xlsx'\n",
    "df.to_excel(destination_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbea42b",
   "metadata": {},
   "source": [
    "**Analysis_set_labeled_with_BiLSTM_v1.xlsx is our Task2.xlsx**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71456eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis_set_labeled_with_BiLSTM_v1.xlsx is our Task2.xlsx\n",
    "destination_file = 'Task2.xlsx'\n",
    "df_application.to_excel(destination_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6749752f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1f6654",
   "metadata": {},
   "source": [
    "## 2. Slower Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72d95005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|                                                                | 1/524226 [00:00<42:31:11,  3.42it/s]C:\\Users\\HUAWEI\\AppData\\Local\\Temp\\ipykernel_95808\\2286040654.py:15: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if not if_company_id_in_companies_name:#若没有找到公司ID（为空），则跳过\n",
      "Processing:   0%|                                                               | 376/524226 [00:06<2:23:32, 60.83it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m opposite_impact_company_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m company_id \u001b[38;5;129;01min\u001b[39;00m same_impact_company_ID_set:\n\u001b[1;32m---> 50\u001b[0m     company_name \u001b[38;5;241m=\u001b[39m nodes_df[nodes_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:ID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m company_id][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     51\u001b[0m     same_impact_company_list\u001b[38;5;241m.\u001b[39mappend(company_name)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m company_id \u001b[38;5;129;01min\u001b[39;00m opposite_impact_company_ID_set:\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:3798\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3796\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   3797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_bool_array(key)\n\u001b[0;32m   3800\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:3852\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3849\u001b[0m \u001b[38;5;66;03m# check_bool_indexer will throw exception if Series key cannot\u001b[39;00m\n\u001b[0;32m   3850\u001b[0m \u001b[38;5;66;03m# be reindexed to match DataFrame rows\u001b[39;00m\n\u001b[0;32m   3851\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, key)\n\u001b[1;32m-> 3852\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   3853\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take_with_is_copy(indexer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm  # 导入tqdm模块\n",
    "\n",
    "# # Step 3: 遍历Application_set.xlsx表格的每一行\n",
    "# for index, row in tqdm(df.iterrows(), total=len(df), desc='Processing'):\n",
    "#     explicit_companies = row['Explicit_Company'].split(', ')\n",
    "    \n",
    "#     # Step 3.1: 创建两个集合，构造相同影响的公司域和相反影响的公司域\n",
    "#     same_impact_company_ID_set = set()\n",
    "#     opposite_impact_company_ID_set = set()\n",
    "    \n",
    "#     # Step 3.2: 遍历Explicit_Company中的每一个公司\n",
    "#     for company in explicit_companies:\n",
    "#         # 查找公司ID\n",
    "#         if_company_id_in_companies_name = nodes_df[nodes_df['company_name'] == company][':ID'].values\n",
    "#         if not if_company_id_in_companies_name:#若没有找到公司ID（为空），则跳过\n",
    "#             continue\n",
    "#         company_id = if_company_id_in_companies_name[0]\n",
    "        \n",
    "#         # 在hidy.relationships.invest.csv和hidy.relationships.supply.csv两个单向关系的表格中搜索相关公司ID\n",
    "#         invest_related = invest_df[invest_df[':START_ID'] == company_id]\n",
    "#         supply_related = supply_df[supply_df[':START_ID'] == company_id]\n",
    "#         # 将相关行的':END_ID'都放入集合\n",
    "#         same_impact_company_ID_set.update(set(invest_related[':END_ID'].values))\n",
    "#         same_impact_company_ID_set.update(set(supply_related[':END_ID'].values))\n",
    "\n",
    "#         # 在hidy.relationships.cooperate.csv和hidy.relationships.same_industry.csv两个双向关系的表格中搜索相关公司ID对应的行\n",
    "#         cooperate_related = cooperate_df[(cooperate_df[':START_ID'] == company_id) | (cooperate_df[':END_ID'] == company_id)]\n",
    "#         same_industry_related = same_industry_df[(same_industry_df[':START_ID'] == company_id) | (same_industry_df[':END_ID'] == company_id)]\n",
    "#         # 将相关行的':START_ID'和':END_ID'都放入集合\n",
    "#         same_impact_company_ID_set.update(set(cooperate_related[':START_ID'].values))\n",
    "#         same_impact_company_ID_set.update(set(cooperate_related[':END_ID'].values))\n",
    "#         same_impact_company_ID_set.update(set(same_industry_related[':START_ID'].values))\n",
    "#         same_impact_company_ID_set.update(set(same_industry_related[':END_ID'].values))\n",
    "\n",
    "#         # 在hidy.relationships.compete.csv和hidy.relationships.dispute.csv两个双向关系的表格中搜索相关公司ID对应的行\n",
    "#         compete_related = compete_df[(compete_df[':START_ID'] == company_id) | (compete_df[':END_ID'] == company_id)]\n",
    "#         dispute_related = dispute_df[(dispute_df[':START_ID'] == company_id) | (dispute_df[':END_ID'] == company_id)]\n",
    "#         # 将相关行的':START_ID'和':END_ID'都放入集合\n",
    "#         opposite_impact_company_ID_set.update(set(compete_related[':START_ID'].values))\n",
    "#         opposite_impact_company_ID_set.update(set(compete_related[':END_ID'].values))\n",
    "#         opposite_impact_company_ID_set.update(set(dispute_related[':START_ID'].values))\n",
    "#         opposite_impact_company_ID_set.update(set(dispute_related[':END_ID'].values))\n",
    "\n",
    "    \n",
    "#     # Step 3.4: 根据公司ID获取公司的中文名并存入相应列表\n",
    "#     same_impact_company_list = []\n",
    "#     opposite_impact_company_list = []\n",
    "    \n",
    "#     for company_id in same_impact_company_ID_set:\n",
    "#         company_name = nodes_df[nodes_df[':ID'] == company_id]['company_name'].values[0]\n",
    "#         same_impact_company_list.append(company_name)\n",
    "\n",
    "#     for company_id in opposite_impact_company_ID_set:\n",
    "#         company_name = nodes_df[nodes_df[':ID'] == company_id]['company_name'].values[0]\n",
    "#         opposite_impact_company_list.append(company_name)\n",
    "\n",
    "\n",
    "#     # Step 3.5: 根据label值进行填充\n",
    "#     if row['label'] == 1:\n",
    "#         df.at[index, 'Implicit_Positive_Company'] = ', '.join(same_impact_company_list) if same_impact_company_list else 'None'\n",
    "#         df.at[index, 'Implicit_Negative_Company'] = ', '.join(opposite_impact_company_list) if opposite_impact_company_list else 'None'\n",
    "#     elif row['label'] == 0:\n",
    "#         df.at[index, 'Implicit_Positive_Company'] = ', '.join(opposite_impact_company_list) if opposite_impact_company_list else 'None'\n",
    "#         df.at[index, 'Implicit_Negative_Company'] = ', '.join(same_impact_company_list) if same_impact_company_list else 'None'\n",
    "\n",
    "# # Step 4: 将结果存储到Analysis_set.xlsx\n",
    "# destination_file = r'D:\\\\ProjectHub\\\\Jupyter Notebook\\\\DSAA 5002 DM\\\\DM-Project\\\\Result_dataset\\\\Analysis_set_BiLSTM\\\\Analysis_set_labeled_with_BiLSTM.xlsx'\n",
    "# df.to_excel(destination_file, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
